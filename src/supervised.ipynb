{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8oAFT3fveI9A"
   },
   "source": [
    "- (Gaussian) Multinomial Naive Bayes with Grid Search\n",
    "- Logistic Regression\n",
    "- Support Vector Machines\n",
    "- Decision Tree\n",
    "- Random Forest & Bagging Classifier\n",
    "- Boosting XGBoost\n",
    "- Neural Nets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IQk1WIEveOgs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rhythmsyed/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rhythmsyed/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rhythmsyed/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/rhythmsyed/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from LanguageModels.Word2Vec import Word2Vec\n",
    "from Preprocessing.LemmatizerPreprocessor import LemmatizerPreprocessor\n",
    "from Preprocessing.DataLoader import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../data/processed/data.p\",'rb')\n",
    "data = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open(\"../data/processed/labels.p\",'rb')\n",
    "labels = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings: (1450, 200)\n",
      "label: (1450,)\n"
     ]
    }
   ],
   "source": [
    "label = labels[:,0]\n",
    "print('embeddings: {}'.format(data.shape))\n",
    "print('label: {}'.format(label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of Nones\n",
    "# for i in range(label.shape[0]):\n",
    "#     print(label[i])\n",
    "#     if label[i] == None:\n",
    "#         print(i)\n",
    "# 299 -> 448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings: (1299, 200)\n",
      "label: (1299,)\n"
     ]
    }
   ],
   "source": [
    "label = np.concatenate((label[:298], label[449::]), 0)\n",
    "label=label.astype('int')\n",
    "data = np.concatenate((data[:298], data[449::]), 0)\n",
    "print('embeddings: {}'.format(data.shape))\n",
    "print('label: {}'.format(label.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine: Multi-Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1039, 200) (260, 200) (1039,) (260,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=42, stratify=label)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svc = SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6660250240615977"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train = clf.predict(X_train)\n",
    "accuracy_score(y_train, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 15,  18,   0,   2,   0,   0,   0,   0,   0,   0,  19],\n",
       "       [  0,  87,   0,   3,   0,   0,   0,   0,   0,   0,  23],\n",
       "       [  0,  12,   0,   1,   0,   0,   0,   0,   0,   0,  10],\n",
       "       [  0,  26,   0,  26,   0,   0,   0,   0,   0,   0,  34],\n",
       "       [  0,  18,   0,   3,   6,   0,   0,   0,   0,   0,  17],\n",
       "       [  1,  13,   0,   5,   0,   0,   0,   0,   0,   0,  17],\n",
       "       [  0,   6,   0,   2,   0,   0,   1,   0,   0,   0,   9],\n",
       "       [  0,  10,   0,   6,   0,   0,   0,   0,   0,   0,  31],\n",
       "       [  0,   5,   0,   1,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  1,  23,   0,   4,   0,   0,   0,   0,   0,   4,  20],\n",
       "       [  1,   4,   0,   2,   0,   0,   0,   0,   0,   0, 553]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6384615384615384"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = clf.predict(X_test)\n",
    "accuracy_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6,   5,   0,   1,   0,   0,   0,   0,   0,   0,   1],\n",
       "       [  0,  18,   0,   1,   0,   0,   0,   0,   0,   0,   9],\n",
       "       [  0,   2,   0,   0,   1,   0,   0,   0,   0,   0,   3],\n",
       "       [  0,   8,   0,   2,   0,   0,   0,   0,   0,   0,  12],\n",
       "       [  0,   6,   0,   0,   1,   0,   0,   0,   0,   0,   4],\n",
       "       [  0,   2,   0,   1,   0,   0,   0,   0,   0,   0,   6],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,   0,   1],\n",
       "       [  0,   6,   0,   1,   0,   0,   0,   0,   0,   0,   5],\n",
       "       [  0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   1],\n",
       "       [  0,   4,   0,   1,   0,   0,   0,   0,   0,   0,   8],\n",
       "       [  0,   1,   0,   0,   0,   0,   0,   0,   0,   0, 139]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression & Evaluation of Different Types of Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Linear Regression (No Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.6195824222295991\n",
      "Training Accuracy: 0.4464624164733535\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "print(\"Training Accuracy: \" + str(reg.score(X_train, y_train)))\n",
    "print(\"Training Accuracy: \" + str(reg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression (L2 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5454773795823153\n",
      "Testing Accuracy: 0.5169477691965991\n",
      "{'alpha': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "parameters = {'alpha':[1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.5, 1, 2, 5, 10]}\n",
    "rid = Ridge()\n",
    "clf = GridSearchCV(rid, parameters, cv=10, verbose=1)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Training Accuracy: \" + str(clf.score(X_train, y_train)))\n",
    "print(\"Testing Accuracy: \" + str(clf.score(X_test, y_test)))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression (L1 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5869160764837922\n",
      "Testing Accuracy: 0.4985604037169039\n",
      "{'alpha': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "parameters = {'alpha':[1e-5, 1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.5, 1, 2, 5, 10, 100]}\n",
    "\n",
    "las = Lasso(max_iter = 10000)\n",
    "clf = GridSearchCV(las, parameters, cv=10, verbose=1)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Training Accuracy: \" + str(clf.score(X_train, y_train)))\n",
    "print(\"Testing Accuracy: \" + str(clf.score(X_test, y_test)))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet Regression (L1 + L2 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 84 candidates, totalling 840 fits\n",
      "Training Accuracy: 0.5675894111134874\n",
      "Testing Accuracy: 0.5207644959410633\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 840 out of 840 | elapsed:   16.0s finished\n"
     ]
    }
   ],
   "source": [
    "parameters = {'alpha':[1e-5, 1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.5, 1, 2, 5, 10, 100], 'l1_ratio':[0.05, 0.1, 0.15, 0.25, 0.5, 0.75, 1]}\n",
    "\n",
    "las = ElasticNet(max_iter = 10000)\n",
    "clf = GridSearchCV(las, parameters, cv=10, verbose=1)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Training Accuracy: \" + str(clf.score(X_train, y_train)))\n",
    "print(\"Testing Accuracy: \" + str(clf.score(X_test, y_test)))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test on Multiple Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Training SVM ***\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    5.9s finished\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}, Test Score: 0.6384615384615384\n",
      "\n",
      "*** Training GaussianProcess ***\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/gaussian_process/gpc.py:434: ConvergenceWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00021604,  0.00333817]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 12, 'warnflag': 2}\n",
      "  ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  4.8min finished\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/gaussian_process/gpc.py:434: ConvergenceWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-6.13026958e-05,  1.28690100e-04]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 11, 'warnflag': 2}\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'kernel': 1**2 * RBF(length_scale=1)}, Test Score: 0.6615384615384615\n",
      "\n",
      "*** Training LogisticRegression ***\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'max_iter': 5000, 'random_state': 0}, Test Score: 0.6038461538461538\n",
      "\n",
      "*** Training DecisionTree ***\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'max_depth': 5}, Test Score: 0.49615384615384617\n",
      "\n",
      "*** Training RandomForest ***\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best Params: {'max_depth': 5, 'max_features': 1, 'n_estimators': 10}, Test Score: 0.5384615384615384\n",
      "\n",
      "*** Training MLP ***\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'alpha': 1, 'max_iter': 5000}, Test Score: 0.5692307692307692\n",
      "\n",
      "*** Training AdaBoost ***\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 100}, Test Score: 0.5384615384615384\n",
      "\n",
      "*** Training NaiveBayes ***\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best Params: {}, Test Score: 0.5884615384615385\n",
      "\n",
      "*** Training BaggingClassifier ***\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.4s finished\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/rhythmsyed/miniconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'base_estimator': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False), 'n_estimators': 10, 'random_state': 0}, Test Score: 0.5384615384615384\n",
      "{'SVM': 0.6384615384615384, 'GaussianProcess': 0.6615384615384615, 'LogisticRegression': 0.6038461538461538, 'DecisionTree': 0.49615384615384617, 'RandomForest': 0.5384615384615384, 'MLP': 0.5692307692307692, 'AdaBoost': 0.5384615384615384, 'NaiveBayes': 0.5884615384615385, 'BaggingClassifier': 0.5384615384615384}\n"
     ]
    }
   ],
   "source": [
    "# names = [\"Linear SVM\", \"RBF SVM\", \"Gaussian Process\", \"Logistic Regression\"\n",
    "#          \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "#          \"Naive Bayes\", \"Bagging Classifier\"]\n",
    "\n",
    "parameters = {\n",
    "    'SVM': {'kernel': ['linear', 'rbf'], 'C':[0.01, 0.1, 1], 'gamma': ['scale']},\n",
    "    'GaussianProcess': {'kernel': [1.0 * RBF(1.0)]},\n",
    "    'LogisticRegression': {'random_state': [0], 'max_iter': [5000]},\n",
    "    'DecisionTree': {'max_depth': [5]},\n",
    "    'RandomForest': {'max_depth': [5], 'n_estimators': [10], 'max_features': [1]},\n",
    "    'MLP': {'alpha': [1], 'max_iter': [5000]},\n",
    "    'AdaBoost': {'n_estimators': [100]},\n",
    "    'NaiveBayes': {},\n",
    "    'BaggingClassifier': {'base_estimator': [SVC()], 'n_estimators': [10], 'random_state': [0]}\n",
    "}\n",
    "\n",
    "classifiers = {\n",
    "    'SVM': SVC(),\n",
    "    'GaussianProcess': GaussianProcessClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'MLP': MLPClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'NaiveBayes': GaussianNB(),\n",
    "    'BaggingClassifier': BaggingClassifier(base_estimator=SVC(), n_estimators=10, random_state=0)\n",
    "}\n",
    "\n",
    "score_dict = {}\n",
    "for name in classifiers.keys():\n",
    "    print('\\n*** Training {} ***'.format(name))\n",
    "    clf = GridSearchCV(classifiers[name], parameters[name], cv=5, verbose=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print('Best Params: {}, Test Score: {}'.format(clf.best_params_, score))\n",
    "    score_dict[name] = score\n",
    "print(score_dict)"
   ]
  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebalancing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1299, 200)\n",
      "(1299,)\n",
      "(599, 200)\n",
      "(599,)\n",
      "Counter({1: 113, 4: 113, 6: 113, 2: 113, 8: 113, 3: 113, 5: 113, 7: 113, 10: 113, 9: 113})\n"
     ]
    }
   ],
   "source": [
    "oversample = SMOTE()\n",
    "def f(i):\n",
    "    if i == 11:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "a = np.where(label == 11)\n",
    "print(data.shape)\n",
    "print(label.shape)\n",
    "\n",
    "data_pos = np.delete(data, a, axis=0)\n",
    "label_pos = np.delete(label, a)\n",
    "print(data_pos.shape)\n",
    "print(label_pos.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_pos, label_pos, test_size=0.2, random_state=42, stratify=label_pos)\n",
    "\n",
    "X_train_rebal, y_train_rebal = oversample.fit_resample(X_train, y_train)\n",
    "print(Counter(y_train_rebal.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass classification, positive labels only, unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       1.00      0.23      0.38       120\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.23       120\n",
      "   macro avg       0.10      0.02      0.04       120\n",
      "weighted avg       1.00      0.23      0.38       120\n",
      "\n",
      "RBF SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.62      0.48         8\n",
      "           2       0.89      0.31      0.46        80\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.32      0.32      0.32        22\n",
      "           5       0.18      0.40      0.25         5\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.08      0.50      0.14         2\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.08      0.33      0.12         3\n",
      "\n",
      "    accuracy                           0.34       120\n",
      "   macro avg       0.19      0.25      0.18       120\n",
      "weighted avg       0.69      0.34      0.41       120\n",
      "\n",
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.75      0.57         8\n",
      "           2       0.93      0.34      0.50        76\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.36      0.35      0.36        23\n",
      "           5       0.27      0.43      0.33         7\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.08      1.00      0.15         1\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.08      0.20      0.11         5\n",
      "\n",
      "    accuracy                           0.38       120\n",
      "   macro avg       0.22      0.31      0.20       120\n",
      "weighted avg       0.71      0.38      0.45       120\n",
      "\n",
      "Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.27      0.29        15\n",
      "           2       0.25      0.27      0.26        26\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.27      0.21      0.24        28\n",
      "           5       0.09      0.06      0.07        16\n",
      "           6       0.11      0.17      0.13         6\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00         6\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.16       120\n",
      "   macro avg       0.10      0.10      0.10       120\n",
      "weighted avg       0.17      0.16      0.16       120\n",
      "\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.58      0.56        12\n",
      "           2       0.79      0.31      0.44        72\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.41      0.35      0.38        26\n",
      "           5       0.18      0.40      0.25         5\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.08      1.00      0.15         1\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.08      0.33      0.12         3\n",
      "\n",
      "    accuracy                           0.35       120\n",
      "   macro avg       0.21      0.30      0.19       120\n",
      "weighted avg       0.62      0.35      0.42       120\n",
      "\n",
      "Neural Net\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.67      0.55         9\n",
      "           2       0.89      0.37      0.53        67\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.50      0.46      0.48        24\n",
      "           5       0.36      0.36      0.36        11\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.08      1.00      0.15         1\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.23      0.38      0.29         8\n",
      "\n",
      "    accuracy                           0.42       120\n",
      "   macro avg       0.25      0.32      0.24       120\n",
      "weighted avg       0.68      0.42      0.48       120\n",
      "\n",
      "AdaBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.64      0.26      0.37        69\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.27      0.21      0.24        28\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         7\n",
      "           8       0.08      0.12      0.10         8\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.21       120\n",
      "   macro avg       0.10      0.06      0.07       120\n",
      "weighted avg       0.44      0.21      0.28       120\n",
      "\n",
      "Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.41      0.47        17\n",
      "           2       0.43      0.43      0.43        28\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.23      0.31      0.26        16\n",
      "           5       0.45      0.45      0.45        11\n",
      "           6       0.11      0.10      0.11        10\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.33      0.25      0.29        16\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.54      0.41      0.47        17\n",
      "\n",
      "    accuracy                           0.34       120\n",
      "   macro avg       0.26      0.24      0.25       120\n",
      "weighted avg       0.38      0.34      0.36       120\n",
      "\n",
      "Bagging Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       1.00      0.23      0.38       120\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.23       120\n",
      "   macro avg       0.10      0.02      0.04       120\n",
      "weighted avg       1.00      0.23      0.38       120\n",
      "\n",
      "{'Linear SVM': 0.23333333333333334, 'RBF SVM': 0.3416666666666667, 'Logistic Regression': 0.375, 'Decision Tree': 0.15833333333333333, 'Random Forest': 0.35, 'Neural Net': 0.4166666666666667, 'AdaBoost': 0.20833333333333334, 'Naive Bayes': 0.3416666666666667, 'Bagging Classifier': 0.23333333333333334}\n"
     ]
    }
   ],
   "source": [
    "names = [\"Linear SVM\", \"RBF SVM\", \"Logistic Regression\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"Bagging Classifier\"]\n",
    "         \n",
    "classifiers = [\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    # GaussianProcessClassifier(1.0 * RBF(1.0), n_jobs=-1),\n",
    "    LogisticRegression(random_state=0, max_iter = 5000),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    MLPClassifier(alpha=1, max_iter=5000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    BaggingClassifier(base_estimator=SVC(),\n",
    "                        n_estimators=10, random_state=0)]\n",
    "\n",
    "score_dict = dict()\n",
    "for name, clf in zip(names, classifiers):\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        score_dict[name] = score\n",
    "        print(name)\n",
    "        print(classification_report(clf.predict(X_test), y_test, zero_division=0))\n",
    "print(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass classification, positive labels only, balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.43      0.44        14\n",
      "           2       0.36      0.59      0.44        17\n",
      "           3       0.50      0.13      0.21        23\n",
      "           4       0.18      0.44      0.26         9\n",
      "           5       0.27      0.43      0.33         7\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.33      0.19      0.24        21\n",
      "           9       0.50      0.07      0.12        14\n",
      "          10       0.38      0.45      0.42        11\n",
      "\n",
      "    accuracy                           0.30       120\n",
      "   macro avg       0.30      0.27      0.25       120\n",
      "weighted avg       0.38      0.30      0.29       120\n",
      "\n",
      "RBF SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.42      0.40        12\n",
      "           2       0.64      0.33      0.44        54\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.32      0.28      0.30        25\n",
      "           5       0.18      0.29      0.22         7\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.08      0.20      0.12         5\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.31      0.33      0.32        12\n",
      "\n",
      "    accuracy                           0.31       120\n",
      "   macro avg       0.19      0.18      0.18       120\n",
      "weighted avg       0.44      0.31      0.35       120\n",
      "\n",
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.43      0.44        14\n",
      "           2       0.36      0.71      0.48        14\n",
      "           3       0.17      0.09      0.12        11\n",
      "           4       0.27      0.38      0.32        16\n",
      "           5       0.45      0.38      0.42        13\n",
      "           6       0.00      0.00      0.00         6\n",
      "           7       0.00      0.00      0.00         4\n",
      "           8       0.25      0.14      0.18        21\n",
      "           9       0.00      0.00      0.00         7\n",
      "          10       0.46      0.43      0.44        14\n",
      "\n",
      "    accuracy                           0.31       120\n",
      "   macro avg       0.24      0.26      0.24       120\n",
      "weighted avg       0.29      0.31      0.29       120\n",
      "\n",
      "Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.24      0.27        17\n",
      "           2       0.29      0.36      0.32        22\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.27      0.27      0.27        22\n",
      "           5       0.27      0.30      0.29        10\n",
      "           6       0.00      0.00      0.00         6\n",
      "           7       0.00      0.00      0.00         7\n",
      "           8       0.00      0.00      0.00        10\n",
      "           9       0.00      0.00      0.00         9\n",
      "          10       0.23      0.25      0.24        12\n",
      "\n",
      "    accuracy                           0.20       120\n",
      "   macro avg       0.14      0.14      0.14       120\n",
      "weighted avg       0.19      0.20      0.19       120\n",
      "\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.38      0.38        13\n",
      "           2       0.68      0.40      0.51        47\n",
      "           3       0.00      0.00      0.00         7\n",
      "           4       0.18      0.22      0.20        18\n",
      "           5       0.27      0.30      0.29        10\n",
      "           6       0.11      0.50      0.18         2\n",
      "           7       0.25      0.25      0.25         4\n",
      "           8       0.08      0.14      0.11         7\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.31      0.36      0.33        11\n",
      "\n",
      "    accuracy                           0.32       120\n",
      "   macro avg       0.23      0.26      0.22       120\n",
      "weighted avg       0.40      0.32      0.34       120\n",
      "\n",
      "Neural Net\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.33      0.39        18\n",
      "           2       0.14      0.40      0.21        10\n",
      "           3       0.00      0.00      0.00        12\n",
      "           4       0.09      0.29      0.14         7\n",
      "           5       0.36      0.33      0.35        12\n",
      "           6       0.00      0.00      0.00         5\n",
      "           7       0.00      0.00      0.00         6\n",
      "           8       0.42      0.23      0.29        22\n",
      "           9       0.00      0.00      0.00         8\n",
      "          10       0.46      0.30      0.36        20\n",
      "\n",
      "    accuracy                           0.23       120\n",
      "   macro avg       0.19      0.19      0.17       120\n",
      "weighted avg       0.28      0.23      0.23       120\n",
      "\n",
      "AdaBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      0.30      0.26        10\n",
      "           2       0.07      0.40      0.12         5\n",
      "           3       0.33      0.05      0.09        38\n",
      "           4       0.05      0.07      0.06        14\n",
      "           5       0.27      0.25      0.26        12\n",
      "           6       0.11      0.12      0.12         8\n",
      "           7       0.25      0.06      0.09        18\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       0.15      0.22      0.18         9\n",
      "\n",
      "    accuracy                           0.12       120\n",
      "   macro avg       0.15      0.15      0.12       120\n",
      "weighted avg       0.22      0.12      0.12       120\n",
      "\n",
      "Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.45      0.42        11\n",
      "           2       0.43      0.28      0.34        43\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.36      0.40      0.38        20\n",
      "           5       0.18      0.50      0.27         4\n",
      "           6       0.00      0.00      0.00        12\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.17      0.25      0.20         8\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.31      0.21      0.25        19\n",
      "\n",
      "    accuracy                           0.28       120\n",
      "   macro avg       0.18      0.21      0.19       120\n",
      "weighted avg       0.32      0.28      0.28       120\n",
      "\n",
      "Bagging Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.45      0.42        11\n",
      "           2       0.46      0.32      0.38        41\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.18      0.27      0.22        15\n",
      "           5       0.36      0.31      0.33        13\n",
      "           6       0.00      0.00      0.00        13\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.08      0.08      0.08        13\n",
      "           9       0.00      0.00      0.00         7\n",
      "          10       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.23       120\n",
      "   macro avg       0.15      0.14      0.14       120\n",
      "weighted avg       0.27      0.23      0.24       120\n",
      "\n",
      "{'Linear SVM': 0.3, 'RBF SVM': 0.30833333333333335, 'Logistic Regression': 0.30833333333333335, 'Decision Tree': 0.2, 'Random Forest': 0.31666666666666665, 'Neural Net': 0.225, 'AdaBoost': 0.125, 'Naive Bayes': 0.275, 'Bagging Classifier': 0.225}\n"
     ]
    }
   ],
   "source": [
    "names = [\"Linear SVM\", \"RBF SVM\", \"Logistic Regression\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"Bagging Classifier\"]\n",
    "         \n",
    "classifiers = [\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    # GaussianProcessClassifier(1.0 * RBF(1.0), n_jobs=-1),\n",
    "    LogisticRegression(random_state=0, max_iter = 5000),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    MLPClassifier(alpha=1, max_iter=5000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    BaggingClassifier(base_estimator=SVC(),\n",
    "                        n_estimators=10, random_state=0)]\n",
    "\n",
    "score_dict = dict()\n",
    "for name, clf in zip(names, classifiers):\n",
    "        clf.fit(X_train_rebal, y_train_rebal)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        score_dict[name] = score\n",
    "        print(name)\n",
    "        print(classification_report(clf.predict(X_test), y_test, zero_division=0))\n",
    "print(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data score 0.6535129932627527 \n",
      "testing data score 0.6192307692307693\n"
     ]
    }
   ],
   "source": [
    "#yet another logistic regression \n",
    "logReg = LogisticRegression(random_state=0, max_iter = 50000)\n",
    "logReg.fit(X_train, y_train)\n",
    "\n",
    "test_training= logReg.score(X_train, y_train)\n",
    "test_testing = logReg.score(X_test, y_test)\n",
    "\n",
    "print(\"training data score\", test_training, \"\\ntesting data score\", test_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data score 0.6323387872954764 \n",
      "testing data score 0.6076923076923076\n"
     ]
    }
   ],
   "source": [
    "#multiclass logistic regression\n",
    "multiclassLogReg = LogisticRegression(multi_class='ovr')\n",
    "multiclassLogReg.fit(X_train, y_train)\n",
    "\n",
    "multi_test_training= multiclassLogReg.score(X_train, y_train)\n",
    "multi_test_testing = multiclassLogReg.score(X_test, y_test)\n",
    "\n",
    "print(\"training data score\", multi_test_training, \"\\ntesting data score\", multi_test_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jx7DzWnAimTq",
    "outputId": "24ec0751-06f8-4a80-9af2-b8387e4cf9e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Vanilla SVM, https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
    "y = np.array([1, 1, 2, 2])\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X, y)\n",
    "print(clf.predict([[-0.8, -1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jhztfSqVeTgk",
    "outputId": "75675487-7eb7-4e16-e466-f768414b02dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "rng = np.random.RandomState(1)\n",
    "X = rng.randint(5, size=(6, 100))\n",
    "y = np.array([1, 2, 3, 4, 5, 6])\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, y)\n",
    "print(clf.predict(X[2:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kN85KiXXedmH",
    "outputId": "3ff8ead1-ec50-42b5-aa19-dd3dd880e9b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Gaussian NB\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "Y = np.array([1, 1, 1, 2, 2, 2])\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, Y)\n",
    "print(clf.predict([[-0.8, -1]]))\n",
    "\n",
    "clf_pf = GaussianNB()\n",
    "clf_pf.partial_fit(X, Y, np.unique(Y))\n",
    "print(clf_pf.predict([[-0.8, -1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mS0VeOXTf3o_",
    "outputId": "aa5e8046-6733-41df-c997-197215a76886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n",
      "[[9.81579028e-01 1.84209573e-02 1.44796627e-08]\n",
      " [9.71349907e-01 2.86500630e-02 3.01442199e-08]]\n",
      "0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression, https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0, max_iter = 50000).fit(X, y)\n",
    "print(clf.predict(X[:2, :]))\n",
    "\n",
    "print(clf.predict_proba(X[:2, :]))\n",
    "print(clf.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M70ytPdOn7E2",
    "outputId": "a8377286-ae78-48ec-b13c-7eb68ed3d56f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVM for large datasets, https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n",
    "X, y = datasets.load_digits(n_class=9, return_X_y=True)\n",
    "data = X / 16\n",
    "feature_map_nystroem = Nystroem(gamma=.2,\n",
    "                                random_state=1,\n",
    "                                n_components=300)\n",
    "data_transformed = feature_map_nystroem.fit_transform(data)\n",
    "\n",
    "clf = make_pipeline(StandardScaler(),\n",
    "                  LinearSVC(random_state=0, tol=1e-5, max_iter = 50000))\n",
    "clf.fit(data_transformed, y)\n",
    "clf.score(data_transformed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6frSiipjo0y2",
    "outputId": "a842098b-fc12-405a-d97c-290b34469f24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classification, https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X, y)\n",
    "print(clf.predict([[0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MWRILYeStNbb",
    "outputId": "ace8e7e9-6851-4327-902c-38d175cd0d4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.93333333, 1.        , 0.93333333, 0.93333333,\n",
       "       0.86666667, 0.93333333, 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Classifier, https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "iris = load_iris()\n",
    "cross_val_score(clf, iris.data, iris.target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QkLbsnHLqi8X",
    "outputId": "47372b8e-7647-42de-b796-1e96088031fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bagging Classifier, https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n",
    "X, y = make_classification(n_samples=100, n_features=4,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "clf = BaggingClassifier(base_estimator=SVC(),\n",
    "                        n_estimators=10, random_state=0).fit(X, y)\n",
    "clf.predict([[0, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W32gGIvGsWli",
    "outputId": "f1385b58-3e2c-404c-9c13-20c2a28d3b92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.913"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting Classifier, https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "X, y = make_hastie_10_2(random_state=0)\n",
    "X_train, X_test = X[:2000], X[2000:]\n",
    "y_train, y_test = y[:2000], y[2000:]\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "      max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nKka6VdKt2vU",
    "outputId": "ba87a29d-0eff-4825-86ec-ffe7c6803f5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP Classifier, https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "X = [[0., 0.], [1., 1.]]\n",
    "y = [0, 1]\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "clf.fit(X, y)\n",
    "clf.predict([[2., 2.], [-1., -2.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using data pipeline for binary logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SIhPUyNTu3QD"
   },
   "outputs": [],
   "source": [
    "#Using data pipeline\n",
    "\n",
    "data = DataLoader('../data/EMNLP2020.csv').load()\n",
    "\n",
    "# Load preprocessor\n",
    "lp = LemmatizerPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(path='../data/glove.6B/glove.6B.200d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9220955275f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# binary case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/GaTech/Sem5/CS7641-MachineLearning/project/cs7641project/src/LanguageModels/Word2Vec.py\u001b[0m in \u001b[0;36mfeaturize\u001b[0;34m(self, data, preprocessor, mode, remove_unlableled, text_key, primary_label_key, secondary_label_key, neg_sample_class, remove_neg_samples)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremove_unlableled\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprimary_label_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml_proj/lib/python3.6/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0munit_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munit_scale\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_printer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplayed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml_proj/lib/python3.6/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mIProgress\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# #187 #451 #558 #872\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             raise ImportError(\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0;34m\"IProgress not found. Please update jupyter and ipywidgets.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;34m\" See https://ipywidgets.readthedocs.io/en/stable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \"/user_install.html\")\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "# binary case\n",
    "X, y = w2v.featurize(data, lp, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5f090fa18a8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=l)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data score 0.9349670122525919 \n",
      "testing data score 0.9135338345864662\n"
     ]
    }
   ],
   "source": [
    "#logistic regression with binary labels\n",
    "\n",
    "logReg = LogisticRegression(random_state=0, max_iter = 50000)\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "logReg.fit(X_train, y_train)\n",
    "\n",
    "test_training= logReg.score(X_train, y_train)\n",
    "test_testing = logReg.score(X_test, y_test)\n",
    "\n",
    "print(\"training data score\", test_training, \"\\ntesting data score\", test_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "supervised.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
