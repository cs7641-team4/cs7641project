{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "provincial-failing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ryan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ryan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ryan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Ryan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "from LanguageModels.Word2Vec import Word2Vec\n",
    "from LanguageModels.BagOfWords import BagOfWords\n",
    "from LanguageModels.CustomWord2Vec import CustomWord2Vec\n",
    "from Preprocessing.LemmatizerPreprocessor import LemmatizerPreprocessor\n",
    "from Preprocessing.DataLoader import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "\n",
    "\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "future-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = DataLoader('../data/EMNLP2020.csv').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reduced-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessor\n",
    "lp = LemmatizerPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alpine-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load language model\n",
    "\n",
    "## Word2Vec Pretrained\n",
    "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "w2v = Word2Vec(path='../data/glove.6B/glove.6B.200d.txt') \n",
    "\n",
    "## Word2Vec Pretrained + Finetuned\n",
    "# w2v = CustomWord2Vec('../data/glove.6B/glove.6B.200d.finetuned.p')\n",
    "\n",
    "\n",
    "## Custom word2vec\n",
    "# w2v = CustomWord2Vec('../data/customw2v.p')\n",
    "\n",
    "## Bag Of Words\n",
    "# w2v = BagOfWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "technological-tuner",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc4cbba6a35480f91ea671d4e6a5776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1327, 200) (1327, 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1d54f9156f4697bc33a8003e4284b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 200) (627, 1) [10]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bb3f4ff84846109ddc2bf58c13b488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1327, 200) (1327, 1) [1]\n"
     ]
    }
   ],
   "source": [
    "# apply preprocessing and vectorization to create text features\n",
    "\n",
    "#### multilabel case\n",
    "X_multilabel, y_multilabel = w2v.featurize(data, lp, mode='multilabel')\n",
    "# X, y = bow.featurize(data, lp, mode='multilabel')\n",
    "\n",
    "print(X_multilabel.shape, y_multilabel.shape)\n",
    "\n",
    "#### multiclass case\n",
    "X_multiclass, y_multiclass = w2v.featurize(data, lp, mode='multiclass', remove_neg_samples=True)\n",
    "# X, y = bow.featurize(data, lp, mode='multiclass')\n",
    "\n",
    "print(X_multiclass.shape, y_multiclass.shape, max(y_multiclass))\n",
    "\n",
    "#### binary case (note 0=in conference, 1=not in conference)\n",
    "X_binary, y_binary = w2v.featurize(data, lp, mode='binary')\n",
    "# X, y = bow.featurize(data, lp, mode='binary')\n",
    "\n",
    "print(X_binary.shape, y_binary.shape, max(y_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-third",
   "metadata": {},
   "source": [
    "## Plot 2d and 3d projections  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-decision",
   "metadata": {},
   "source": [
    "### Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = (X_binary, y_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_embedded2d = TSNE(n_components=2).fit_transform(X)\n",
    "# X_embedded3d = TSNE(n_components=3).fit_transform(X)\n",
    "\n",
    "X_embedded2d = umap.UMAP(n_components=2).fit_transform(X)\n",
    "X_embedded3d = umap.UMAP(n_components=3).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_embedded2d[:,0], X_embedded2d[:,1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(X_embedded3d[:,0], X_embedded3d[:,1], X_embedded3d[:,2], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-translator",
   "metadata": {},
   "source": [
    "### Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "applicable-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = (X_multiclass, y_multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "random-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_embedded2d = TSNE(n_components=2).fit_transform(X)\n",
    "# X_embedded3d = TSNE(n_components=3).fit_transform(X)\n",
    "\n",
    "X_embedded2d = umap.UMAP(n_components=2).fit_transform(X)\n",
    "X_embedded3d = umap.UMAP(n_components=3).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "spread-viewer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x18e6603ddd8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_embedded2d[:,0], X_embedded2d[:,1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cubic-insurance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x18e65e34e10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(X_embedded3d[:,0], X_embedded3d[:,1], X_embedded3d[:,2], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y.reshape(-1,), test_size=0.33, random_state=42)\n",
    "\n",
    "# clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(y_train, clf.predict(X_train) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-street",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = {}\n",
    "# for label in y:\n",
    "#     try:\n",
    "#         counts[label[0]] += 1\n",
    "#     except:\n",
    "#         counts.update({label[0]:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# init = [w2v.convert(['language', 'model', 'natural']), w2v.convert(['server', 'cyber', 'latency'])]\n",
    "\n",
    "# kmeans = KMeans(n_clusters=2, random_state=0, init=np.array(init)).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-ratio",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
